{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23839 entries, 0 to 23838\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   postcode   23839 non-null  int64  \n",
      " 1   region1    23839 non-null  object \n",
      " 2   region2    23839 non-null  object \n",
      " 3   region3    23839 non-null  object \n",
      " 4   latitude   23839 non-null  float64\n",
      " 5   longitude  23839 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:86: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "'''Data Cleaning'''\n",
    "\n",
    "# Loading Data\n",
    "order_payment_dataset = pd.read_csv('./order_payments_dataset.csv')\n",
    "orders_dataset = pd.read_csv('./orders_dataset.csv')\n",
    "customer_reviews_dataset = pd.read_csv('./customer_reviews_dataset.csv')\n",
    "customers_dataset = pd.read_csv('./customers_dataset.csv')\n",
    "order_items_dataset = pd.read_csv('./order_items_dataset.csv')\n",
    "products_dataset = pd.read_csv('./products_dataset.csv')\n",
    "sellers_dataset = pd.read_csv('./sellers_dataset.csv')\n",
    "geo_dataset = pd.read_csv('./Clean_geodata.csv')\n",
    "geo_dataset.info()\n",
    "#link to Clean_geodata: https://drive.google.com/file/d/1ZsuJWBLdsbfWI7GQNgKMZj-a1bh2wDK_/view?usp=sharing\n",
    "\n",
    "#Dataset Transformation\n",
    "\n",
    "#1. geo-dataset transdormation:\n",
    "geo_dataset_seller = geo_dataset #seller zipcode dataset\n",
    "geo_dataset_seller.rename(columns = {'region1':'region1_seller', 'region2':'region2_seller', \n",
    "                              'region3':'region3_seller','latitude':'latitude_seller','longitude':'longitude_seller'}, inplace = True) \n",
    "geo_dataset = pd.read_csv('./Clean_geodata.csv')\n",
    "geo_dataset_consumer = geo_dataset #consumer zipcode dataset\n",
    "geo_dataset_consumer.rename(columns = {'region1':'region1_con', 'region2':'region2_con', \n",
    "                              'region3':'region3_con','latitude':'latitude_con','longitude':'longitude_con'}, inplace = True) \n",
    "#2.seller and consumer zip code transform\n",
    "sellers_dataset['seller_zip_code_prefix'] = sellers_dataset['seller_zip_code_prefix'].astype(int)\n",
    "customers_dataset['customer_zip_code_prefix'] = customers_dataset['customer_zip_code_prefix'].astype(int)\n",
    "\n",
    "# Merge Dataset \n",
    "final=order_payment_dataset.merge(orders_dataset,on='order_id',how = 'left')\n",
    "final=final.merge(customer_reviews_dataset,how = 'left',on='order_id')\n",
    "final=final.merge(customers_dataset,how = 'left',on='customer_id')\n",
    "final=final.merge(order_items_dataset,how = 'left',on='order_id')\n",
    "final=final.merge(products_dataset,how = 'left',on='product_id')\n",
    "final=final.merge(sellers_dataset,how = 'left',on='seller_id')\n",
    "final=final.merge(geo_dataset_seller,how = 'left',left_on='seller_zip_code_prefix',right_on='postcode')\n",
    "final=final.merge(geo_dataset_consumer,how = 'left',left_on='customer_zip_code_prefix',right_on='postcode')\n",
    "#print(final.shape)\n",
    "#final.isnull().sum()\n",
    "\n",
    "#genertate sell-con Euclidean_dist\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    # Radius of earth in kilometers is 6371\n",
    "    km = 6371* c\n",
    "    return km\n",
    "\n",
    "final['Eucl'] = [haversine(final.longitude_seller[i],final.latitude_seller[i],final.longitude_con[i],final.latitude_con[i]) for i in range(len(final))]\n",
    "\n",
    "# Extract survey review data\n",
    "survey_review_data = final[['order_id','survey_score','survey_review_title','survey_review_content']]\n",
    "final = final.drop(['survey_review_title','survey_review_content','postcode_x','postcode_y'],axis=1)\n",
    "#drop null values: clean dataset, good for analysis\n",
    "final.dropna(inplace=True)\n",
    "\n",
    "# Clean time variable\n",
    "final['order_approved_at'] = pd.to_datetime(final['order_approved_at'])\n",
    "final['order_customer_delivery_date'] = pd.to_datetime(final['order_customer_delivery_date'])\n",
    "final['shipping_limit_date'] = pd.to_datetime(final['shipping_limit_date'])\n",
    "final['order_estimated_delivery_date'] = pd.to_datetime(final['order_estimated_delivery_date'])\n",
    "\n",
    "final['days']=(final['order_customer_delivery_date'].subtract(final['order_approved_at'])).dt.total_seconds() / (3600 * 24)\n",
    "final['shipping_limit_days']=(final['shipping_limit_date'].subtract(final['order_approved_at'])).dt.total_seconds() / (3600 * 24)\n",
    "final['estimated_days']=(final['order_estimated_delivery_date'].subtract(final['order_approved_at'])).dt.total_seconds() / (3600 * 24)\n",
    "# a limit for sellers to send their products to the logistics\n",
    "#negative values means delivered before the order [they are outliers, should be deleted]\n",
    "final = final[final['days'].notna()]\n",
    "final['delivery_state']=(final['order_estimated_delivery_date']).subtract(final['order_customer_delivery_date']).dt.total_seconds() / (3600 * 24)\n",
    "#negative: delayed, positive: pre deliverd\n",
    "\n",
    "#drop null values: clean dataset\n",
    "final.dropna(inplace=True)\n",
    "\n",
    "# aggregate product information\n",
    "order_mass = final[['order_id','product_weight_g','product_length_cm','product_height_cm','product_width_cm']]\n",
    "order_mass['product_mass'] = order_mass['product_length_cm'] * order_mass['product_height_cm'] * order_mass['product_width_cm']\n",
    "order_mass = order_mass[['order_id','product_mass','product_weight_g']]\n",
    "order_mass = order_mass.groupby('order_id')['product_mass','product_weight_g'].sum()\n",
    "order_mass = order_mass.rename(columns={\"order_id\": \"order_id\", \"product_mass\": \"order_mass\", \"product_weight_g\": \"order_weight_g\"})\n",
    "final=final.merge(order_mass,how = 'left',on='order_id')\n",
    "\n",
    "# Clean distance between sellers and customers\n",
    "final['distance']= 0\n",
    "\n",
    "for i in range(final.shape[0]):\n",
    "    if final['region3_seller'][i]==final['region3_con'][i]:\n",
    "        final['distance'][i]=1\n",
    "    elif final['region2_seller'][i]==final['region2_con'][i]:\n",
    "        final['distance'][i]=2\n",
    "    elif final['region1_seller'][i]==final['region1_con'][i]:\n",
    "        final['distance'][i]=3\n",
    "    else: \n",
    "        final['distance'][i]=4\n",
    "\n",
    "# 1: same region 3\n",
    "# 2: same region 2, not same region 3\n",
    "# 3: same region 1, not same region 2\n",
    "# 4: not same region 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Add a new column \"Category\" to classified products into 10 categories\n",
    "baby=['bebes','brinquedos','fraldas_higiene','fashion_roupa_infanto_juvenil']\n",
    "commerce=['agro_industria_e_comercio','industria_comercio_e_negocios']\n",
    "food_drinks=['la_cuisine','bebidas','alimentos','market_place','alimentos_bebidas']\n",
    "fashion=['flores','livros_importados','fashion_roupa_feminina','fashion_esporte','fashion_underwear_e_moda_praia','fashion_roupa_masculina','malas_acessorios','relogios_presentes','fashion_calcados','fashion_bolsas_e_acessorios']\n",
    "home_and_office=['utilidades_domesticas','casa_conforto','artigos_de_natal','artigos_de_festas','casa_conforto_2','portateis_casa_forno_e_cafe','papelaria','pet_shop','construcao_ferramentas_construcao','construcao_ferramentas_ferramentas','ferramentas_jardim','construcao_ferramentas_jardim','casa_construcao','construcao_ferramentas_iluminacao','construcao_ferramentas_seguranca','sinalizacao_e_seguranca','seguros_e_servicos']\n",
    "sport_and_entertainment=['musica','cine_foto','artes_e_artesanato','cool_stuff','livros_importados','livros_interesse_geral','artes','dvds_blu_ray','cds_dvds_musicais','instrumentos_musicais','esporte_lazer']\n",
    "furniture=['cama_mesa_banho','moveis_cozinha_area_de_servico_jantar_e_jardim','moveis_decoracao','moveis_escritorio','moveis_colchao_e_estofado','moveis_sala','moveis_quarto']\n",
    "auto=['automotivo']\n",
    "beauty=['beleza_saude','perfumaria']\n",
    "electric_appliance=['informatica_acessorios','telefonia','tablets_impressao_imagem','telefonia_fixa','eletroportateis','consoles_games','audio','climatizacao','eletronicos','eletrodomesticos','livros_tecnicos','pcs','eletrodomesticos_2']\n",
    "\n",
    "Category = []\n",
    "NaN = np.nan\n",
    "final['Category']=NaN\n",
    "i = 0\n",
    "for c in final['product_category_name']:\n",
    "    for x in baby: \n",
    "        if c == x: \n",
    "             #  Category.append('Baby')\n",
    "            final.Category.iloc[i]='Baby'\n",
    "    for x in commerce:\n",
    "        if c == x:\n",
    "            final.Category.iloc[i]='Commerce'\n",
    "    for x in food_drinks:\n",
    "        if c == x:\n",
    "            final.Category.iloc[i]='Food_drinks'\n",
    "    for x in fashion:\n",
    "        if c == x:\n",
    "            final.Category.iloc[i]='Fashion'\n",
    "    for x in home_and_office:\n",
    "        if c == x:\n",
    "            final.Category.iloc[i]='Home_and_office'\n",
    "    for x in sport_and_entertainment:\n",
    "        if c == x:\n",
    "            final.Category.iloc[i]='Sports_and_entertainment'\n",
    "    for x in furniture:\n",
    "        if c == x:\n",
    "            final.Category.iloc[i]='Furniture'\n",
    "    for x in auto:\n",
    "        if c == x:\n",
    "            final.Category.iloc[i]='Auto'\n",
    "    for x in beauty:\n",
    "        if c == x:\n",
    "            final.Category.iloc[i]='Beauty'\n",
    "    for x in electric_appliance:\n",
    "        if c == x:\n",
    "            final.Category.iloc[i]='Electric_appliance'\n",
    "    i = i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature columns: \n",
      "Index(['payment_value', 'price', 'freight_value', 'Eucl',\n",
      "       'shipping_limit_days', 'estimated_days', 'order_mass', 'order_weight_g',\n",
      "       'distance'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eucl</th>\n",
       "      <th>estimated_days</th>\n",
       "      <th>pre_days</th>\n",
       "      <th>days</th>\n",
       "      <th>better</th>\n",
       "      <th>accurate_pre</th>\n",
       "      <th>accurate_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81576</th>\n",
       "      <td>371.860350</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93075</th>\n",
       "      <td>816.399684</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>1009.528584</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99057</th>\n",
       "      <td>734.199506</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50779</th>\n",
       "      <td>3184.634332</td>\n",
       "      <td>46.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77989</th>\n",
       "      <td>1446.609525</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94593</th>\n",
       "      <td>255.830694</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56084</th>\n",
       "      <td>143.736180</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52157</th>\n",
       "      <td>117.716922</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11655</th>\n",
       "      <td>520.488856</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62164</th>\n",
       "      <td>2166.453258</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26048</th>\n",
       "      <td>812.297318</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59549</th>\n",
       "      <td>1281.557936</td>\n",
       "      <td>43.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>331.274837</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82895</th>\n",
       "      <td>16.740486</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104355</th>\n",
       "      <td>8.211360</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88262</th>\n",
       "      <td>568.274225</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49262</th>\n",
       "      <td>85.163823</td>\n",
       "      <td>62.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13022</th>\n",
       "      <td>354.106632</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32736</th>\n",
       "      <td>318.102411</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Eucl  estimated_days  pre_days  days  better  accurate_pre  \\\n",
       "81576    371.860350            22.0      12.0   5.0       1             0   \n",
       "93075    816.399684            21.0      12.0  12.0       1             1   \n",
       "12110   1009.528584            26.0       7.0   7.0       1             1   \n",
       "99057    734.199506            23.0      14.0   5.0       1             0   \n",
       "50779   3184.634332            46.0      21.0  19.0       1             0   \n",
       "77989   1446.609525            40.0      24.0  13.0       1             0   \n",
       "94593    255.830694            38.0      13.0  17.0       0             0   \n",
       "56084    143.736180            23.0      10.0  12.0       0             0   \n",
       "52157    117.716922            15.0       8.0   3.0       1             0   \n",
       "11655    520.488856            28.0      15.0  10.0       1             0   \n",
       "62164   2166.453258            44.0      22.0  21.0       1             0   \n",
       "26048    812.297318            31.0      11.0  12.0       0             0   \n",
       "59549   1281.557936            43.0      15.0  15.0       1             1   \n",
       "6635     331.274837            34.0       7.0   7.0       1             1   \n",
       "82895     16.740486             3.0       3.0   3.0       2             1   \n",
       "104355     8.211360            26.0       7.0   5.0       1             0   \n",
       "88262    568.274225            24.0      11.0  11.0       1             1   \n",
       "49262     85.163823            62.0      13.0  13.0       1             1   \n",
       "13022    354.106632            21.0      13.0  12.0       1             0   \n",
       "32736    318.102411            18.0       6.0   4.0       1             0   \n",
       "\n",
       "        accurate_exp  \n",
       "81576              0  \n",
       "93075              0  \n",
       "12110              0  \n",
       "99057              0  \n",
       "50779              0  \n",
       "77989              0  \n",
       "94593              0  \n",
       "56084              0  \n",
       "52157              0  \n",
       "11655              0  \n",
       "62164              0  \n",
       "26048              0  \n",
       "59549              0  \n",
       "6635               0  \n",
       "82895              1  \n",
       "104355             0  \n",
       "88262              0  \n",
       "49262              0  \n",
       "13022              0  \n",
       "32736              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17208\n",
      "1     5556\n",
      "Name: accurate_pre, dtype: int64 1:pre is accurate,0:pre is not acc\n",
      "0    22421\n",
      "1      343\n",
      "Name: accurate_exp, dtype: int64 1:exp is accurate,0:exp is not acc\n",
      "1    15902\n",
      "0     6586\n",
      "Name: better, dtype: int64 1:prediction is better,0:expected is better\n",
      "proportion of 1 0.7071326929918179\n"
     ]
    }
   ],
   "source": [
    "# feature&labels\n",
    "\n",
    "final_regression= final.drop(['order_id','payment_sequential','payment_type','payment_installments','customer_id', 'order_status','order_purchase_timestamp', 'order_approved_at','order_carrier_delivery_date', 'order_customer_delivery_date','order_estimated_delivery_date', 'review_id','survey_score','survey_send_date', 'survey_completion_date', 'customer_unique_id','customer_zip_code_prefix', 'customer_city', 'customer_state','order_item_id', 'product_id', 'seller_id', 'product_category_name','product_name_lenght', 'product_description_lenght','product_photos_qty', 'product_weight_g', 'product_length_cm','product_height_cm', 'product_width_cm', 'seller_zip_code_prefix','seller_city', 'seller_state', 'region1_seller', 'region2_seller','region3_seller', 'region1_con', 'region2_con', 'region3_con','shipping_limit_date','latitude_seller','longitude_seller','latitude_con','longitude_con','delivery_state','Category'],axis=1)\n",
    "\n",
    "features, label = final_regression.drop(['days'], axis=1), final_regression['days']\n",
    "print(f\"feature columns: \\n{features.columns}\\n\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=30)\n",
    "X_train2 = X_train.drop(['estimated_days'], axis=1)\n",
    "X_test2 = X_test.drop(['estimated_days'], axis=1)\n",
    "\n",
    "##ExtraTreesRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "regr = ExtraTreesRegressor()\n",
    "regr.fit(X_train2, y_train)\n",
    "ypred = regr.predict(X_test2)\n",
    "\n",
    "X_test['pre_days'] = ypred\n",
    "X_test['days'] = y_test\n",
    "result = X_test.drop(['payment_value','price','freight_value','shipping_limit_days','order_mass','order_weight_g','distance'],axis=1)\n",
    "\n",
    "result['estimated_days'] = result['estimated_days'].add(.5).round()\n",
    "result['pre_days'] = result['pre_days'].add(.5).round()\n",
    "result['days'] = result['days'].add(.5).round()\n",
    "\n",
    "#comparation\n",
    "result['better'] = 0\n",
    "result.index.tolist()\n",
    "\n",
    "\n",
    "for i in result.index.tolist():\n",
    "    if result['pre_days'][i] <= result['days'][i] and result['pre_days'][i] > result['estimated_days'][i]:\n",
    "        result['better'][i] = 1\n",
    "    \n",
    "    elif result['pre_days'][i] >= result['days'][i] and result['pre_days'][i] < result['estimated_days'][i]:\n",
    "        result['better'][i] = 1\n",
    "        \n",
    "    elif result['pre_days'][i] >= result['days'][i] and result['estimated_days'] [i] < result['days'][i]:\n",
    "        result['better'][i] = 1\n",
    "        \n",
    "    elif result['pre_days'][i] == result['estimated_days'][i]:\n",
    "        result['better'][i] = 2\n",
    "\n",
    "#better?\n",
    "result_filtered = result[result['better'] < 2] \n",
    "\n",
    "#accurate?\n",
    "result['accurate_pre'] = 0\n",
    "result.index.tolist()\n",
    "\n",
    "for i in result.index.tolist():\n",
    "    if result['pre_days'][i] == result['days'][i]:\n",
    "        result['accurate_pre'][i] = 1\n",
    "\n",
    "result['accurate_exp'] = 0\n",
    "result.index.tolist()\n",
    "\n",
    "for i in result.index.tolist():\n",
    "    if result['estimated_days'][i] == result['days'][i]:\n",
    "        result['accurate_exp'][i] = 1\n",
    "        \n",
    "display(result.head(20))\n",
    "print(result['accurate_pre'].value_counts(),'1:pre is accurate,0:pre is not acc')\n",
    "print(result['accurate_exp'].value_counts(),'1:exp is accurate,0:exp is not acc')\n",
    "print(result_filtered['better'].value_counts(),'1:prediction is better,0:expected is better')\n",
    "print('proportion of 1',sum(result_filtered['better'])/result_filtered.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''classification'''\n",
    "#Dataset for Analysis\n",
    "final2= final.drop(['order_id','payment_sequential','payment_type','payment_installments','customer_id', 'order_status','order_purchase_timestamp', 'order_approved_at','order_carrier_delivery_date', \n",
    "                    'order_customer_delivery_date','order_estimated_delivery_date', 'review_id','survey_score','survey_send_date', 'survey_completion_date', 'customer_unique_id',\n",
    "                    'customer_zip_code_prefix', 'customer_city', 'customer_state','order_item_id', 'product_id', 'seller_id', 'product_category_name',\n",
    "                    'product_name_lenght', 'product_description_lenght',\n",
    "                    'product_photos_qty', 'product_weight_g', 'product_length_cm',\n",
    "                    'product_height_cm', 'product_width_cm', 'seller_zip_code_prefix',\n",
    "                    'seller_city', 'seller_state', 'region1_seller', 'region2_seller',\n",
    "                    'region3_seller', 'region1_con', 'region2_con', 'region3_con','shipping_limit_date','latitude_seller','longitude_seller','latitude_con','latitude_con'],axis=1)\n",
    "\n",
    "# feature&labels\n",
    "final_num=final2._get_numeric_data()\n",
    "bins = [-np.inf,0,5,10,30,np.inf]\n",
    "final_num['group'] = pd.cut(final_num['days'].values, bins,labels=[1,2,3,4,5])\n",
    "\n",
    "## devide features and label\n",
    "features, label = final_num.drop([\"group\",'days','delivery_state'], axis=1), final_num['group']\n",
    "print(f\"feature columns: \\n{features.columns}\\n\")\n",
    "\n",
    "## split train dataset and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=30)\n",
    "\n",
    "##Decision tree classifier\n",
    "## find best para\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "param_grid = {'max_depth':[3,5,7,11,100],'ccp_alpha': [0,0.0001]}\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=10)\n",
    "dt_model_grid = GridSearchCV (dt_model, param_grid, cv=10)\n",
    "dt_model_grid.fit (X_train, y_train)\n",
    "\n",
    "## train model\n",
    "dt_model_tuned = dt_model_grid.best_estimator_\n",
    "test_preds = dt_model_tuned.predict(X_test)\n",
    "train_preds = dt_model_tuned.predict(X_train)\n",
    "print (dt_model_grid.best_params_)\n",
    "print (\"Train accuracy:\", dt_model_tuned.score(X_train,y_train))\n",
    "print (\"Test accuracy:\", dt_model_tuned.score(X_test,y_test))\n",
    "\n",
    "## give out report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report (y_test, test_preds))\n",
    "\n",
    "## show the confusion metrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_dt = confusion_matrix (y_test, test_preds)\n",
    "print (\"Confusion matrix: \\n\", cm_dt)\n",
    "\n",
    "#visualization\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import os\n",
    "feature_names = list(X_test.columns)\n",
    "class_names = ['1', '2', '3','4','5','6']\n",
    "'''\n",
    "Write your code below\n",
    "'''\n",
    "dot_data = tree.export_graphviz(dt_model_tuned, out_file=None,feature_names=feature_names,\\\n",
    "                                class_names=class_names, filled=True,\\\n",
    "                                rounded=True,special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n",
    "\n",
    "##Random Forest Classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForestClassifier\n",
    "\n",
    "#set parameters\n",
    "param_grid_rf={'n_estimators': [5,7,9,11],'max_depth': [11,50,100,200,300],'min_samples_leaf': [50,100],'ccp_alpha':[0, 0.0001]}\n",
    "\n",
    "#build and train model\n",
    "RF_model= RandomForestClassifier(random_state=30)\n",
    "RF_grid= GridSearchCV(RF_model, param_grid_rf)\n",
    "RF_grid.fit(X_train,y_train)\n",
    "\n",
    "#results\n",
    "print ('best parameter:',RF_grid.best_params_)\n",
    "print ('best score:',RF_grid.best_score_,end='\\n\\n')\n",
    "\n",
    "#build the best model\n",
    "RF_model_tuned = RF_grid.best_estimator_\n",
    "RF_test_preds = RF_model_tuned.predict(X_test)\n",
    "RF_train_preds = RF_model_tuned.predict(X_train)\n",
    "\n",
    "#accuracy\n",
    "print (\"Train accuracy:\", RF_model_tuned.score(X_train,y_train))\n",
    "print (\"Test accuracy:\", RF_model_tuned.score(X_test,y_test))\n",
    "\n",
    "## give out report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report (y_test, RF_test_preds))\n",
    "\n",
    "## show the confusion metrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_dt = confusion_matrix (y_test, RF_test_preds)\n",
    "print (\"Confusion matrix: \\n\", cm_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data Description'''\n",
    "df_order_by_category=final[['product_id','Category']].groupby('Category').count()\n",
    "df_order_by_category.rename(columns={'product_id':'product_count'},inplace=True)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 20\n",
    "fig, ax = plt.subplots(figsize=(10, 20), subplot_kw=dict(aspect=\"equal\"))\n",
    "\n",
    "Name = list(df_order_by_category.index)\n",
    "\n",
    "data = list(df_order_by_category.product_count)\n",
    "\n",
    "wedges, texts = ax.pie(data, wedgeprops=dict(width=0.5), startangle=-40, textprops={'fontsize': 10})\n",
    "\n",
    "bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "kw = dict(arrowprops=dict(arrowstyle=\"-\"),\n",
    "          bbox=bbox_props, zorder=0, va=\"center\")\n",
    "\n",
    "for i, p in enumerate(wedges):\n",
    "    ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "    y = np.sin(np.deg2rad(ang))\n",
    "    x = np.cos(np.deg2rad(ang))\n",
    "    horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "    connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n",
    "    kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "    ax.annotate(Name[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),\n",
    "                horizontalalignment=horizontalalignment, **kw)\n",
    "\n",
    "ax.set_title(\"Market share of our dataset\",y=1.08)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## --Graph 2: show the customer review (title/contents) key words of orders-------------\n",
    "# import basic\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# create txt for customer review title & contents\n",
    "import csv\n",
    "survey_review_data.to_csv('survey_review_data.csv')\n",
    "\n",
    "review_contents = pd.DataFrame(survey_review_data['survey_review_content'])\n",
    "review_contents.dropna(inplace=True)\n",
    "\n",
    "review_title = pd.DataFrame(survey_review_data['survey_review_title'])\n",
    "review_title.dropna(inplace=True)\n",
    "\n",
    "review_title.to_csv('review_title.txt', index=False)\n",
    "review_contents.to_csv('review_contents.txt', index=False)\n",
    "\n",
    "text_title = open(\"review_title.txt\",encoding='utf8').read()\n",
    "text_title = text_title.replace('\\n',\"\").replace(\"\\u3000\",\"\")\n",
    "\n",
    "text_contents = open(\"review_contents.txt\",encoding='utf8').read()\n",
    "text_contents = text_title.replace('\\n',\"\").replace(\"\\u3000\",\"\")\n",
    "\n",
    "# create word cloud\n",
    "mask = np.array(Image.open(\"Brazil-flag.png\"))\n",
    "wordcloud_contents = WordCloud(background_color=\"white\", max_words=1000, mask=mask).generate(text_contents)\n",
    "\n",
    "image_colors = ImageColorGenerator(mask)\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.imshow(wordcloud_contents.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig(\"contents_flag\", format=\"png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "wordcloud_title = WordCloud(background_color=\"white\", max_words=1000, mask=mask).generate(text_title)\n",
    "\n",
    "image_colors = ImageColorGenerator(mask)\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.imshow(wordcloud_title.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig(\"title_flag\", format=\"png\")\n",
    "plt.show()\n",
    "\n",
    "#reference: https://www.datacamp.com/community/tutorials/wordcloud-python\n",
    "\n",
    "## --Graph 3: order payment method-------------\n",
    "order_payment_dataset = pd.read_csv('./order_payments_dataset.csv')\n",
    "order_payment_dataset.describe()\n",
    "payment_type=order_payment_dataset.groupby('payment_type').count()\n",
    "payment_type.rename(columns={'order_id':'Frequency'},inplace=True)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "ax = sns.barplot(x=list(payment_type.index), y='Frequency', data=payment_type)\n",
    "### credit card is the most frequently used method to pay online\n",
    "\n",
    "## --Graph 4: measuring the selling situation-------------\n",
    "orders_dataset = pd.read_csv('./orders_dataset.csv')\n",
    "orders_dataset['year']=orders_dataset['order_purchase_timestamp'].apply(lambda x: x[:4])\n",
    "orders_dataset['month']=orders_dataset['order_purchase_timestamp'].apply(lambda x: x[5:7])\n",
    "sale_month_year=orders_dataset.groupby(['year','month']).count()\n",
    "sale_month_year.rename(columns={'order_id':'Frequency'},inplace=True)\n",
    "sale_month_year=sale_month_year['Frequency']\n",
    "sale_month_year.plot.bar()\n",
    "# it has a increase tendency and Nov, 2017 is the month with most sales. \n",
    "\n",
    "\n",
    "## --Graph 4: 雷达图 showing the feature of each Category-------------\n",
    "pro_describ=final.groupby('Category').mean()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "featurelist=list(pro_describ.index)\n",
    "Category=list(pro_describ.columns)\n",
    "\n",
    "\n",
    "for i in range(len(Category)):\n",
    "    # 构造数据\n",
    "    values = list(pro_describ[Category[i]])\n",
    "    feature = featurelist\n",
    "    N = len(values)\n",
    "    # 设置雷达图的角度，用于平分切开一个圆面\n",
    "    angles=np.linspace(0, 2*np.pi, N, endpoint=False)\n",
    "    values=np.concatenate((values,[values[0]]))\n",
    "    angles=np.concatenate((angles,[angles[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
